
===============================
Developer: 0x1A7
Tool Name: DESEMAP
===============================
====================================================================
                   D E E P M A P   (Site Link Collector)
====================================================================
Developer : 0x1A7
Version   : 1.0
Python    : 3.10+
====================================================================

  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â• 
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  
  â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  
                       Developer: 0x1A7
====================================================================

-------------
DEEPMAP, bir web sitesindeki tÃ¼m baÄŸlantÄ±larÄ± (HTML linkleri, 
JavaScript dosyalarÄ±ndaki URLâ€™ler, robots.txt ve sitemap.xml iÃ§erikleri)
toplayarak JSON, CSV veya TXT formatÄ±nda kaydeden bir web crawlerâ€™dÄ±r.

AmaÃ§: 
- Web sitelerinin iÃ§ link haritasÄ±nÄ± Ã§Ä±karmak
- GÃ¼venlik taramasÄ± veya OSINT iÅŸlemleri iÃ§in veri toplamak
- EÄŸitim projelerinde crawler mantÄ±ÄŸÄ±nÄ± gÃ¶stermek

====================================================================
âš™ï¸ KURULUM
====================================================================
1. Python 3 (https://www.python.org/downloads) kurulu olmalÄ±dÄ±r.
   â†’ Kurulum sÄ±rasÄ±nda â€œAdd Python to PATHâ€ kutucuÄŸunu iÅŸaretle.

2. Proje dosyalarÄ±:
   - site_link_collector.py
   - install.bat
   - requirements.txt
   - README.txt

3. **install.bat** dosyasÄ±na Ã§ift tÄ±kla.
   - Virtual environment (.venv) oluÅŸturulur
   - Gerekli kÃ¼tÃ¼phaneler (requests, bs4, lxml) otomatik yÃ¼klenir

4. Kurulum tamamlandÄ±ktan sonra terminali aÃ§:
call .venv\Scripts\activate

markdown
Kodu kopyala

5. ProgramÄ± Ã§alÄ±ÅŸtÄ±r:
python desemap.py https://testphp.vulnweb.com --depth 1 --format all

markdown
Kodu kopyala

====================================================================
ğŸ“¦ REQUIREMENTS
====================================================================
`requirements.txt` iÃ§eriÄŸi:
requests>=2.28
beautifulsoup4>=4.12
lxml>=4.9

scss
Kodu kopyala

Python standart kÃ¼tÃ¼phaneleri (ayrÄ±ca yÃ¼klenmez):
argparse
urllib.parse
re
json
csv
sys
time
concurrent.futures
collections

markdown
Kodu kopyala

====================================================================
ğŸ§  KULLANIM Ã–RNEKLERÄ°
====================================================================
â€¢ Temel kullanÄ±m:
python desemap.py https://site.com

java
Kodu kopyala

â€¢ Derin tarama (2 seviye):
python desemap.py https://site.com --depth 2

javascript
Kodu kopyala

â€¢ JSON + CSV + TXT Ã§Ä±ktÄ±sÄ± almak:
python desemap.py https://site.com --format all

yaml
Kodu kopyala

â€¢ robots.txt ve sitemap.xml dahil tarama:
python desemap.py https://site.com --follow-sitemap yes

pgsql
Kodu kopyala

â€¢ BaÅŸka domainlere de geÃ§ (off-domain tarama):
python desemap.py https://site.com --follow-external yes

markdown
Kodu kopyala

====================================================================
ğŸ§© KOD YAPISI AÃ‡IKLAMASI
====================================================================
desemap.py
â”‚
â”œâ”€â”€ normalize() â†’ Linkleri dÃ¼zenler, geÃ§ersizleri filtreler
â”œâ”€â”€ fetch_text() â†’ URLâ€™den sayfa iÃ§eriÄŸini indirir
â”œâ”€â”€ parse_robots() â†’ robots.txt iÃ§eriÄŸini analiz eder
â”œâ”€â”€ parse_sitemap() â†’ sitemap.xmlâ€™den linkleri Ã§Ä±karÄ±r
â”œâ”€â”€ parse_html_for_links() â†’ HTMLâ€™deki <a>, <img>, <script>, <iframe> vb. tagâ€™lardan linkleri toplar
â”œâ”€â”€ collect() â†’ TÃ¼m tarama dÃ¶ngÃ¼sÃ¼nÃ¼ yÃ¶netir (derinlik, filtreleme, hÄ±z)
â”œâ”€â”€ save_json/csv/txt() â†’ Ã‡Ä±ktÄ±larÄ± belirtilen formatlarda kaydeder
â””â”€â”€ main() â†’ ArgÃ¼manlarÄ± okur, taramayÄ± baÅŸlatÄ±r

markdown
Kodu kopyala

KullanÄ±lan temel kÃ¼tÃ¼phaneler:
- **requests** â†’ Web sayfalarÄ±nÄ± Ã§ekmek
- **BeautifulSoup (bs4)** â†’ HTML & XML parse etmek
- **lxml** â†’ HÄ±zlÄ± XML analiz motoru
- **concurrent.futures** â†’ Ã‡oklu thread (paralel istek)
- **argparse** â†’ Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± yÃ¶netmek
====================================================================
KOMUT ANLAM : 
====================================================================
--depth N
BaÅŸlangÄ±Ã§ sayfasÄ±ndan kaÃ§ "link sÄ±Ã§ramasÄ±" yapÄ±lacaÄŸÄ±nÄ± belirler. 0 = sadece start, 1 = start + starttaki linkler, vb.

--concurrency N
AynÄ± anda kaÃ§ paralel istek atÄ±lsÄ±n (thread sayÄ±sÄ±).

--obey-robots yes|no
yes (default) ise robots.txtâ€™de Disallow olan URLâ€™leri atlar.

--follow-external yes|no
no (default) ise sadece aynÄ± domain iÃ§indeki linkleri takip eder. yes ile dÄ±ÅŸ domainlere de geÃ§er.

--follow-sitemap yes|no
robots.txt iÃ§indeki Sitemap URLâ€™lerini indirir ve iÃ§indeki linkleri kuyruÄŸa ekler.

--js-scan yes|no
Script dosyalarÄ±nÄ± indirip iÃ§indeki URLâ€™leri regex ile tarar (ucuz, yÃ¼zeysel).

--timeout SECONDS
Her HTTP isteÄŸi iÃ§in zaman aÅŸÄ±mÄ±.

--max-pages N
Maksimum taranacak sayfa limiti (koruma amaÃ§lÄ±).

--output NAME ve --format json|csv|txt|all
Ã‡Ä±ktÄ± dosya adÄ±nÄ± ve formatÄ±nÄ± kontrol eder (all hepsini kaydeder).
====================================================================

====================================================================
ğŸ§¾ Ã–RNEK Ã‡IKTI
====================================================================
[i] Tarama baÅŸlÄ±yor: https://testphp.vulnweb.com (depth=1)
[+] JSON kaydedildi: site_links.json
[+] CSV kaydedildi: site_links.csv
[+] TXT kaydedildi: site_links.txt
[i] Toplam bulunan URL sayÄ±sÄ± (sources tablosuna gÃ¶re): 42

markdown
Kodu kopyala

====================================================================
ğŸ’¡ NOTLAR
====================================================================
- Program varsayÄ±lan olarak robots.txt kurallarÄ±na uyar.
- Maksimum sayfa limiti: 2000 (parametre: --max-pages)
- HTTP timeout sÃ¼resi: 12 saniye (parametre: --timeout)
- JSON Ã§Ä±ktÄ±sÄ±nda her URL iÃ§in:
  â€¢ status_code, content_type, parent sayfa, depth ve title bilgisi bulunur.

====================================================================
ğŸ“š GELÄ°ÅTÄ°RÄ°CÄ° BÄ°LGÄ°SÄ°
====================================================================
Developer : 0x1A7  
Tool Name : DEEPMAP  
Year      : 2025  
Language  : Python 3 (UTF-8)  
====================================================================